# GuÃ­a de OptimizaciÃ³n del Entrenamiento â€” OCENSA-ML

> Â¿Tu modelo BERT (BETO) se demora demasiado en tu computadora personal?  
> AquÃ­ tienes las estrategias mÃ¡s efectivas para acelerar el entrenamiento sin sacrificar calidad.

---

## Resumen RÃ¡pido

| TÃ©cnica | Ahorro estimado de tiempo | Dificultad | Impacto en calidad |
|---------|--------------------------|------------|-------------------|
| Entrenamiento con **GPU en la nube** (Colab) | 5-10x mÃ¡s rÃ¡pido | â­ FÃ¡cil | Sin impacto |
| **Mixed Precision** (fp16) | 2-3x mÃ¡s rÃ¡pido | â­ FÃ¡cil | MÃ­nimo |
| Reducir **max_length** de 256 a 128 | ~2x mÃ¡s rÃ¡pido | â­ FÃ¡cil | Bajo-medio |
| **Congelar capas** de BERT | 1.5-2x mÃ¡s rÃ¡pido | â­â­ Medio | Bajo |
| **Gradient Accumulation** | Permite batch mÃ¡s grande sin mÃ¡s RAM | â­â­ Medio | Positivo |
| Usar modelo mÃ¡s pequeÃ±o (**DistilBETO**) | 2-3x mÃ¡s rÃ¡pido | â­â­ Medio | Bajo-medio |
| **Early Stopping** | Evita Ã©pocas innecesarias | â­ FÃ¡cil | Positivo |
| Reducir **Ã©pocas** (15 â†’ 8-10) | ~40% menos tiempo | â­ FÃ¡cil | Monitorear |

---

## 1. Usa Google Colab (GPU Gratis) â­ RECOMENDADO

La forma mÃ¡s rÃ¡pida de acelerar tu entrenamiento es usar una GPU en la nube. Google Colab ofrece GPUs Tesla T4 gratis.

### Pasos:

1. Ve a [Google Colab](https://colab.research.google.com)
2. Sube tu proyecto o clÃ³nalo desde GitHub:
   ```python
   !git clone https://github.com/tu-usuario/Modelo-Heuris.git
   %cd Modelo-Heuris
   ```
3. Activa la GPU: **Entorno de ejecuciÃ³n â†’ Cambiar tipo de entorno â†’ GPU (T4)**
4. Instala dependencias:
   ```python
   !pip install torch transformers tqdm scikit-learn pandas matplotlib seaborn imageio
   ```
5. Ejecuta el entrenamiento:
   ```python
   %cd fase3_entrenamiento_bert
   !python train_bert_model.py
   ```

> ğŸ’¡ **Tiempo estimado**: En CPU local â†’ 24-48 horas. En GPU Colab T4 â†’ 2-4 horas.

---

## 2. Mixed Precision Training (fp16) â­ RECOMENDADO

Entrena con nÃºmeros de 16 bits en lugar de 32 bits. Reduce uso de memoria y acelera los cÃ¡lculos en GPUs modernas.

### Cambios en `train_bert_model.py` (Fase 3):

```python
# Agregar al inicio del archivo
from torch.cuda.amp import autocast, GradScaler

# Crear scaler UNA SOLA VEZ antes del loop de Ã©pocas
scaler = GradScaler()
```

Modificar la funciÃ³n `train_epoch` para recibir el `scaler` como parÃ¡metro:

```python
def train_epoch(model, data_loader, optimizer, scheduler, device, scaler, visualizer=None, causa_weights=None):
    model.train()
    total_loss = 0

    label_smoothing = CONFIG.get("label_smoothing", 0.0)
    criterion_modo = nn.CrossEntropyLoss(label_smoothing=label_smoothing)
    if causa_weights is not None:
        causa_weights = causa_weights.to(device)
    criterion_causa = nn.CrossEntropyLoss(label_smoothing=label_smoothing, weight=causa_weights)
    criterion_prioridad = nn.CrossEntropyLoss(label_smoothing=label_smoothing)

    progress_bar = tqdm(data_loader, desc="Entrenando", leave=False)

    for batch in progress_bar:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        modo_labels = batch['modo_label'].to(device)
        causa_labels = batch['causa_label'].to(device)
        prioridad_labels = batch['prioridad_label'].to(device)

        optimizer.zero_grad()

        # âœ… Mixed Precision
        with autocast():
            modo_logits, causa_logits, prioridad_logits = model(input_ids, attention_mask)
            loss_modo = criterion_modo(modo_logits, modo_labels)
            loss_causa = criterion_causa(causa_logits, causa_labels)
            loss_prioridad = criterion_prioridad(prioridad_logits, prioridad_labels)
            loss = 0.1 * loss_modo + 0.6 * loss_causa + 0.3 * loss_prioridad

        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()
        scheduler.step()

        loss_val = loss.item()
        total_loss += loss_val
        progress_bar.set_postfix({'loss': f'{loss_val:.4f}'})

        if visualizer:
            visualizer.update_batch(loss_val)

    return total_loss / len(data_loader)
```

> ğŸ’¡ **Resultado**: ~2x mÃ¡s rÃ¡pido en GPU, reduce memoria VRAM ~40%.

---

## 3. Reducir `max_length` (256 â†’ 128)

Tu configuraciÃ³n actual usa `max_length: 256`. La mayorÃ­a de las descripciones de falla industrial son cortas. Reducir a 128 tokens corta el tiempo casi a la mitad.

### Cambio en el CONFIG:

```python
# En fase3_entrenamiento_bert/train_bert_model.py
CONFIG = {
    "max_length": 128,  # Antes: 256 â€” La mayorÃ­a de textos caben en 128
    # ... resto igual
}
```

### CÃ³mo verificar que no pierdes informaciÃ³n:

```python
import pandas as pd
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("dccuchile/bert-base-spanish-wwm-cased")
df = pd.read_csv("data/synthetic_training_data.csv")

# Ver la distribuciÃ³n de longitudes de tokens
texts = df['descripcion'].astype(str).tolist()
encoded = tokenizer(texts, add_special_tokens=True, truncation=False)
lengths = pd.Series([len(ids) for ids in encoded['input_ids']])
print(f"Percentil 95: {lengths.quantile(0.95):.0f} tokens")
print(f"Percentil 99: {lengths.quantile(0.99):.0f} tokens")
print(f"MÃ¡ximo: {lengths.max()} tokens")
```

Si el percentil 95 es menor a 128, puedes usar 128 sin problema.

> ğŸ’¡ **Resultado**: ~2x mÃ¡s rÃ¡pido (la complejidad de BERT es O(nÂ²) con respecto a la longitud).

---

## 4. Congelar Capas de BERT

BERT tiene 12 capas de transformer. Las capas inferiores capturan gramÃ¡tica general y rara vez necesitan re-entrenarse. Congela las primeras 8-10 capas y solo entrena las Ãºltimas 2-4.

### Agregar despuÃ©s de crear el modelo:

```python
# Congelar embeddings y las primeras 10 capas del encoder
for param in model.bert.embeddings.parameters():
    param.requires_grad = False

for i, layer in enumerate(model.bert.encoder.layer):
    if i < 10:  # Congelar capas 0-9, entrenar solo 10-11
        for param in layer.parameters():
            param.requires_grad = False

# Verificar parÃ¡metros entrenables
total = sum(p.numel() for p in model.parameters())
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"ParÃ¡metros: {trainable:,} entrenables de {total:,} totales ({trainable/total*100:.1f}%)")
```

> ğŸ’¡ **Resultado**: ~1.5-2x mÃ¡s rÃ¡pido, menos memoria. Solo entrena ~15% de los parÃ¡metros.

---

## 5. Gradient Accumulation

Si tu GPU/CPU no tiene suficiente memoria para `batch_size=16`, puedes simular un batch grande acumulando gradientes en varios pasos pequeÃ±os.

### Ejemplo (simular batch 16 con mini-batches de 4):

```python
CONFIG = {
    "batch_size": 4,                 # Batch real en memoria
    "gradient_accumulation_steps": 4, # 4 * 4 = 16 batch efectivo
    # ...
}

# En el loop de entrenamiento:
accumulation_steps = CONFIG.get("gradient_accumulation_steps", 1)
optimizer.zero_grad()

for step, batch in enumerate(progress_bar):
    input_ids = batch['input_ids'].to(device)
    attention_mask = batch['attention_mask'].to(device)
    # ... forward pass y cÃ¡lculo de loss (igual que en train_epoch) ...
    loss = loss / accumulation_steps
    loss.backward()

    if (step + 1) % accumulation_steps == 0:
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()
```

> ğŸ’¡ **Resultado**: Permite entrenar en GPUs con poca VRAM (4-6 GB) o incluso en CPU con menos RAM.

---

## 6. Usar un Modelo MÃ¡s PequeÃ±o (DistilBETO)

Si el tiempo sigue siendo un problema, considera usar una versiÃ³n destilada de BERT en espaÃ±ol que es ~40% mÃ¡s pequeÃ±a y 60% mÃ¡s rÃ¡pida.

### Cambio en CONFIG:

```python
CONFIG = {
    # OpciÃ³n 1: DistilBERT multilingÃ¼e (incluye espaÃ±ol)
    "model_name": "distilbert-base-multilingual-cased",

    # OpciÃ³n 2: BETO original (actual)
    # "model_name": "dccuchile/bert-base-spanish-wwm-cased",
}
```

> âš ï¸ **Nota**: DistilBERT multilingÃ¼e puede ser ligeramente menos preciso que BETO para texto tÃ©cnico en espaÃ±ol, pero la diferencia suele ser menor al 2-3% en F1.

---

## 7. Early Stopping (Parada Anticipada)

Evita entrenar Ã©pocas innecesarias si el modelo ya dejÃ³ de mejorar. Fase 5 ya lo tiene, pero Fase 3 no.

### Agregar al loop principal de Fase 3:

```python
best_val_f1 = 0
patience_counter = 0
patience_limit = 3  # Detener si no mejora en 3 Ã©pocas

for epoch in range(CONFIG["epochs"]):
    train_loss = train_epoch(...)
    val_results = evaluate(...)
    
    current_f1 = val_results["causa_f1"]  # Monitorear la mÃ©trica mÃ¡s importante
    
    if current_f1 > best_val_f1:
        best_val_f1 = current_f1
        patience_counter = 0
        # Guardar el mejor modelo
        torch.save(model.state_dict(), "best_model.bin")
    else:
        patience_counter += 1
    
    if patience_counter >= patience_limit:
        print(f"[Early Stopping] Sin mejora en {patience_limit} Ã©pocas. Deteniendo.")
        break
```

> ğŸ’¡ **Resultado**: Si el modelo converge en la Ã©poca 8, te ahorras 7 Ã©pocas (~47% del tiempo).

---

## 8. Reducir Ã‰pocas y Monitorear

En tu configuraciÃ³n actual tienes `epochs: 15`. Para iteraciÃ³n rÃ¡pida:

```python
CONFIG = {
    "epochs": 5,  # Para pruebas rÃ¡pidas
    # "epochs": 15,  # Para entrenamiento final
}
```

Consejo: Entrena primero 5 Ã©pocas para verificar que todo funciona, luego escala a 15.

---

## 9. OptimizaciÃ³n del DataLoader

Mejora la velocidad de carga de datos con mÃ¡s workers y memoria pinned:

```python
# En la creaciÃ³n del DataLoader
train_loader = DataLoader(
    train_dataset,
    batch_size=CONFIG["batch_size"],
    shuffle=True,
    num_workers=4,        # Usar 4 workers para cargar datos en paralelo
    pin_memory=True,      # Carga mÃ¡s rÃ¡pida a GPU
    persistent_workers=True,  # No reiniciar workers entre Ã©pocas (requiere num_workers > 0)
)
```

> ğŸ’¡ En **Windows**, `num_workers > 0` puede causar errores. Si es tu caso, usa `num_workers=0` y elimina `persistent_workers`.

---

## 10. Resumen de Cambios Recomendados por Prioridad

### ğŸŸ¢ Prioridad Alta (Haz esto primero)

| # | Cambio | Archivo | Tiempo de implementaciÃ³n |
|---|--------|---------|-------------------------|
| 1 | Usa Google Colab con GPU T4 | N/A (infraestructura) | 10 minutos |
| 2 | Reduce `max_length` a 128 | `fase3/.../train_bert_model.py` | 1 minuto |
| 3 | Agrega Early Stopping | `fase3/.../train_bert_model.py` | 15 minutos |

### ğŸŸ¡ Prioridad Media (Si necesitas mÃ¡s velocidad)

| # | Cambio | Archivo | Tiempo de implementaciÃ³n |
|---|--------|---------|-------------------------|
| 4 | Activa Mixed Precision (fp16) | `fase3/.../train_bert_model.py` | 20 minutos |
| 5 | Congela capas 0-9 de BERT | `fase3/.../train_bert_model.py` | 10 minutos |
| 6 | Gradient Accumulation (batch=4, accum=4) | `fase3/.../train_bert_model.py` | 15 minutos |

### ğŸ”µ Prioridad Baja (Para experimentaciÃ³n)

| # | Cambio | Archivo | Tiempo de implementaciÃ³n |
|---|--------|---------|-------------------------|
| 7 | Usar DistilBERT multilingÃ¼e | CONFIG en cada script | 5 minutos |
| 8 | Optimizar DataLoader workers | Cada script de entrenamiento | 5 minutos |

---

## ComparaciÃ³n de Tiempos Estimados

| ConfiguraciÃ³n | Tiempo Fase 3 (15 Ã©pocas) | Tiempo Total (3 modelos) |
|---------------|--------------------------|-------------------------|
| CPU sin optimizar (actual) | 8-16 horas | 24-48 horas |
| CPU + max_len=128 + freeze | 3-6 horas | 9-18 horas |
| GPU Colab T4 sin optimizar | 1-2 horas | 3-6 horas |
| GPU Colab T4 + fp16 + freeze | 30-60 min | 1.5-3 horas |
| GPU Colab T4 + fp16 + DistilBERT | 20-40 min | 1-2 horas |

---

## Recursos Adicionales

- [Google Colab](https://colab.research.google.com) â€” GPU gratis
- [Kaggle Notebooks](https://www.kaggle.com/code) â€” GPU P100 gratis (30h/semana)
- [Hugging Face Mixed Precision](https://huggingface.co/docs/transformers/perf_train_gpu_one#fp16-training) â€” DocumentaciÃ³n oficial
- [PyTorch AMP](https://pytorch.org/docs/stable/amp.html) â€” Automatic Mixed Precision

---

> ğŸ“ **Nota**: Todas estas optimizaciones son compatibles entre sÃ­. Puedes combinar Colab + fp16 + freeze + max_len=128 para obtener el mÃ¡ximo beneficio.
